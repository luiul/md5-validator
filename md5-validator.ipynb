{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f256704-6db7-47c3-877d-5df48c47db03",
   "metadata": {},
   "source": [
    "# MD5 Validator\n",
    "\n",
    "Notebook to validate submitted pdf files against submitted md5 checksums. Student id must be checked manually by a tutor.  \n",
    "\n",
    "The first stage of this notebook takes as input I1: \n",
    "- raw HTML files with submitted md5 from students\n",
    "- raw pdf files submitted by students\n",
    "- csv file with student information (Matrikel, Name, Mail, SS (Startsemester), PO (Pr√ºfungsordnung))\n",
    "\n",
    "In the first stage we generate the following output s(I1)=O1: \n",
    "- data frame and CSV file with md5 of pdf files\n",
    "- data frame file with submitted md5 from students\n",
    "- data frame and CSV file with valid submissions\n",
    "- data frame and CSV file with invalid submissions\n",
    "\n",
    "In the first stage, we also rename the pdf files according to the valid submissions data frame. After the first stage, the valid pdf files are graded and stored in the korrigiert directory. \n",
    "\n",
    "The second stage takes as input I2: \n",
    "- graded pdf files \n",
    "\n",
    "In the second stage we generate the following output s(I2)=O2: \n",
    "- encrypted graded pdf files\n",
    "\n",
    "After the graded pdf files are encrypted, they are ready to be uploaded publicly. The encrypted files have an owner key that can open all files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d49a042-e70a-4327-95fe-18c6417a7f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODIFY BEFORE RUNNING STAGE 1!\n",
    "path = 'tx'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8189d30-1df1-4aa1-91f5-45d7d6ea7d90",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4975a0ec-f25e-4965-8cfd-1ff5a332c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import hashlib\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cf3855-b4fc-4142-8149-bf19700bb88c",
   "metadata": {},
   "source": [
    "# Stage 1\n",
    "\n",
    "In this stage we: \n",
    "- Generate MD5 from uploaded PDF files\n",
    "- Store MD5 from PDF files as data frame A\n",
    "- Scrape MD5 from HTML files\n",
    "- Extract name from HTML files\n",
    "- Store scraped MD5 and extracted names as data frame B\n",
    "- Inner join A and B to determine valid submissions; store the resulting data frame C\n",
    "- Read student id data and store it as data frame D\n",
    "- Inner join C and D to get additional information for the valid submissions; store the resulting data frame E\n",
    "\n",
    "Don't forget to normalize strings and remove whitespaces!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f709e8-214b-45e6-8275-2c7f207b651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_md5(path):\n",
    "    '''\n",
    "    Takes in a path, returns list of strings. Iterate all HTML files in the path and scrape the submitted MD5s\n",
    "    '''\n",
    "    # list of all the files in the directory\n",
    "    html_files = glob.glob(path + '/*.html')\n",
    "    \n",
    "    # make empty list to append all the matches\n",
    "    match_list = []\n",
    "    \n",
    "    # iterate all the files in the directory and find matches\n",
    "    for file in html_files: \n",
    "        with open(file) as f: \n",
    "            soup = BeautifulSoup(f, 'lxml')\n",
    "            match = soup.body.text\n",
    "            \n",
    "            # normalize before appending\n",
    "            match = unicodedata.normalize('NFD', match)\n",
    "            match = match.strip()\n",
    "            \n",
    "            match_list.append(match)\n",
    "                  \n",
    "    return match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79f087-9168-4244-8dbf-cd1780c01b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_names(path): \n",
    "    '''\n",
    "    Takes in a path, returns list of strings. Iterate all HTML files in the path and extract student name from the file name\n",
    "    '''\n",
    "    # list of all the files in the directory\n",
    "    html_files = glob.glob(path + '/*.html')\n",
    "    \n",
    "    # make empty list to append all the matches\n",
    "    match_list = []\n",
    "    \n",
    "    # iterate all the files in the directory and find matches\n",
    "    for file in html_files:\n",
    "        # remove directory\n",
    "        file = re.sub(r'\\..+\\/','',file)\n",
    "        \n",
    "        # remove everything after the _ \n",
    "        file = re.sub(r'_.+','',file)\n",
    "        \n",
    "        # normalize before appending\n",
    "        file = unicodedata.normalize('NFD', file)\n",
    "        \n",
    "        # append the result to the list\n",
    "        match_list.append(file)\n",
    "        \n",
    "    return match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e4562b-013a-4968-ac30-55f6e698e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_md5(path):\n",
    "    '''\n",
    "    Takes in a path, returns list of strings. Iterate all files in the path and generate MD5\n",
    "    '''\n",
    "    # list of all the files in the directory\n",
    "    files = glob.glob(path + '/*.*')\n",
    "    \n",
    "    # make empty list to append all the matches\n",
    "    md5_list = []\n",
    "    \n",
    "    # make set of seen items\n",
    "    seen = set(md5_list)\n",
    "    \n",
    "    # iterate all the files in the directory and generate md5; this also removes the duplicates in the files\n",
    "    for file in files:\n",
    "        with open(file, 'rb') as rbf: \n",
    "            content = rbf.read()\n",
    "            h = hashlib.md5(content).hexdigest()\n",
    "            \n",
    "            # normalize before appending\n",
    "            h = unicodedata.normalize('NFD', h)\n",
    "            \n",
    "            if h not in seen: \n",
    "                seen.add(h)\n",
    "                md5_list.append(h)\n",
    "            else: \n",
    "                os.remove(file)\n",
    "    return md5_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd617735-9a8d-48c0-bcf8-8ae8387f457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdf = pd.DataFrame({'MD5':file_to_md5(f'./{path}/pdf')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8ee38-47fd-4c24-b716-1e2c67b12424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb42449-85e2-407d-98ff-2c2168a355bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789d572-be7a-4746-b902-41b938c87914",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdf.to_csv(f'./{path}/pdf-table.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aaa344-5b64-4a07-9bc7-215274a8b52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = pd.DataFrame({'MD5':list_md5(f'./{path}/md5'),'Name':list_names(f'./{path}/md5')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7c242-6427-4dc1-802f-003dd2ca0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4d346f-edfd-47d1-ad54-8ea88d08afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615da5e-a906-4ba0-866a-baeaf295b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(f'./{path}/sub-table.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8985d4b-8267-4369-9983-a8d9b05fac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.merge(df_pdf,df_sub,how='inner',on='MD5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dafd0a7-33fd-43d3-a9a9-6637dbdcfe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5cb2c-4a86-40aa-9e1b-dd9aac4e3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832460d2-6d33-449d-903f-c0d70911b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c0d787-240d-490f-afe6-b8ef325f483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid['Name'] = df_valid['Name'].str.encode('cp273')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b1c09-b77e-4af1-a1fc-ce143b0bc9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f209b-6f74-4e94-ac3a-70b9afc34975",
   "metadata": {},
   "source": [
    "Submitted but not valid: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4364ca-d0b7-41c1-a86a-46ec9bc0a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_not_val = pd.merge(df_valid, df_sub, how='outer',on='MD5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf8d7d-cd2d-4a74-955d-fc3689f03bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_not_val = df_sub_not_val[df_sub_not_val.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a11f5c4-8edd-4227-95e5-8bfd5ffe849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_not_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd3f2b-4c95-46d2-b69f-86960d37dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_not_val.to_csv(f'./{path}/sub-not-val-table.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d2a6a-34b7-4c4d-95e7-c8167fe7ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id = pd.read_csv('./ids.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771fc76-4927-471d-b68e-f1b236bb86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4ab235-ef11-48c9-afed-94e6b86a51b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_id.to_csv('./test-id2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975d346-85db-4afc-ad72-f830196d6b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id['Name'] = df_id['Name'].apply(lambda name : unicodedata.normalize('NFD', name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b8969b-a2f4-4366-bd59-1a62744edac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398653bd-2b28-4ceb-b5f9-a7f340500de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090169fe-2f44-408d-8efb-1cb0dffec605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_id[df_id['Name']==b'Clarissa Schu\\xcc\\x88tt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fade47-c70a-4b28-b267-1a48c97a3ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_id['Name'] = df_id['Name'].apply(lambda name : name.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20965c-ca34-445a-81c6-389a62612078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnr = pd.merge(df_valid, df_id, how='inner',on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450439d8-386b-4476-91c9-ea0f1aa85e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638dc4f-e3a1-4e0c-83a5-36367e3c172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_mnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da6344f-6326-4b97-9837-9fa585275d20",
   "metadata": {},
   "source": [
    "## Check if the following statement is TRUE!\n",
    "\n",
    "If the following is not true, update the (student) IDs table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5732b837-5a8a-486d-aee1-dbe053610c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_valid) == len(df_mnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b53b75-1451-4adf-b834-7294492c5d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnr.to_csv(f'./{path}/valid-table.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a4cc8b-b35c-4bfe-a3aa-6cae930ae7b9",
   "metadata": {},
   "source": [
    "## Rename PDF files\n",
    "\n",
    "Rename the valid submitted PDF files before grading them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f0f45-fcfa-493c-b685-1628ef75f9a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "md5_dic = df_mnr.to_dict()['MD5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e6387-d92f-482e-9fcd-c6c090c213bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrikel_dic = df_mnr.to_dict()['Matrikel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7d9c1-71b5-43e3-8df7-1161a2c457a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_file(path):\n",
    "    files = glob.glob(path + '/*.*')\n",
    "    \n",
    "    for file in files:\n",
    "        with open(file, 'rb') as rbf: \n",
    "            content = rbf.read()\n",
    "            h = hashlib.md5(content).hexdigest()\n",
    "            for key, val in md5_dic.items(): \n",
    "                if val == h: \n",
    "                    os.rename(file, f'./{path}/{matrikel_dic[key]}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbdfc8d-bf11-473b-b541-25671f0deb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_file(f'./{path}/pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daab2ab2-c04e-413c-85ea-05ba46a2d8bc",
   "metadata": {},
   "source": [
    "---\n",
    "**END OF STAGE 1**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac10bfb9-cb38-49dc-a509-9c21cfcc82ab",
   "metadata": {},
   "source": [
    "# Stage 2\n",
    "\n",
    "In this stage we: \n",
    "\n",
    "- encrypt the graded PDF files against the data frame with valid submissions\n",
    "\n",
    "Rerun the whole notebook before Stage 2, to store the data frame with valid submissions in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89adb51-e5b5-4208-b341-b2043bc259cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pikepdf\n",
    "from pikepdf import Pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c355e9b5-3b44-4923-afff-1d9475a95cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration without altering the environment\n",
    "from dotenv import dotenv_values\n",
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f17305f-2f99-4eaa-84a9-95ecb6b91b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OWNER, = config.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7771de73-e168-4e12-a97a-a7d4d38e99af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_file(path_):\n",
    "    os.mkdir(f'./{path}/korrigiert-e')\n",
    "    \n",
    "    files = glob.glob(path_ + '/*.*')\n",
    "    \n",
    "    for file in files:\n",
    "        # print(file)\n",
    "        file_name = file.split('/')[3]\n",
    "        file_name = file_name.split('.')[0]\n",
    "        # print(file_name)\n",
    "        for key, val in matrikel_dic.items(): \n",
    "            if file_name == val: \n",
    "                pdf = Pdf.open(file)    \n",
    "                \n",
    "                pdf.save(f'./{path}/korrigiert-e/{matrikel_dic[key]}-e.pdf', encryption=pikepdf.Encryption(owner=OWNER, user=f'{md5_dic[key]}', R=4)) \n",
    "                # you can change the R from 4 to 6 for 256 aes encryption\n",
    "                pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a414c4b-361a-4dba-a869-1c79dafdad33",
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypt_file(f'./{path}/korrigiert')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d67fe8-0c55-4e79-a9c1-db9a0f002c25",
   "metadata": {},
   "source": [
    "---\n",
    "**END OF STAGE 2**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27032275-d0b3-4365-a4dc-64f044b9da15",
   "metadata": {},
   "source": [
    "**DONE!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c70dde-e5c8-4d6d-a42d-33f010c12404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
